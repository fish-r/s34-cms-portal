{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer to this for installation https://github.com/abetlen/llama-cpp-python#installation-with-openblas--cublas--clblast--metal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.56)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (1.4.50)\n",
      "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.5.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (2023.10.0)\n",
      "Requirement already satisfied: langchain>=0.0.303 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.0.327)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (1.5.8)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (1.24.3)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (2.0.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (4.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (1.26.18)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index) (3.20.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from deprecated>=1.2.9.3->llama_index) (1.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (3.8.4)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (4.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (0.0.54)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain>=0.0.303->llama_index) (2.31.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.65.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama_index) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<4.0->langchain>=0.0.303->llama_index) (1.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index) (2.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama_index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama_index) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.303->llama_index) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk<4.0.0,>=3.8.1->llama_index) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-cpp-python) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-cpp-python) (1.24.3)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index\n",
    "%pip install llama-cpp-python\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)  # Change INFO to DEBUG if you want more extensive logging\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_url=\"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q5_K_M.gguf\",\n",
    "    \n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path=None,\n",
    "    \n",
    "    temperature=0.0,\n",
    "    max_new_tokens=1024,\n",
    "    \n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=3900,  # note, this sets n_ctx in the model_kwargs below, so you don't need to pass it there.\n",
    "    \n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    \n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 4}, # I need to play with this and see if it actually helps\n",
    "    \n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.00599 seconds\n",
      "      |_chunking ->  0.001005 seconds\n",
      "      |_chunking ->  0.000992 seconds\n",
      "      |_chunking ->  0.001004 seconds\n",
      "      |_chunking ->  0.000995 seconds\n",
      "      |_chunking ->  0.000998 seconds\n",
      "      |_chunking ->  0.0 seconds\n",
      "      |_chunking ->  0.0 seconds\n",
      "    |_embedding ->  0.52004 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# Create an index of your documents\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "storage_directory = \"./storage\"\n",
    "\n",
    "documents = SimpleDirectoryReader('./testdata').load_data()\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024,\n",
    "                                               embed_model=\"local\",\n",
    "                                               callback_manager=callback_manager)\n",
    "\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "# Persist the index to disk\n",
    "index.storage_context.persist(persist_dir=storage_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# Now you can load the index from disk when needed, and not rebuild it each time.\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# transcript_directory = \"transcripts/ancient-aliens-official\"\n",
    "storage_directory = \"./storage\"\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024,\n",
    "                                               embed_model=\"local\",\n",
    "                                               callback_manager=callback_manager)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=storage_directory)\n",
    "index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  650.275208 seconds\n",
      "      |_retrieve ->  0.025978 seconds\n",
      "        |_embedding ->  0.024977 seconds\n",
      "      |_synthesize ->  650.247467 seconds\n",
      "        |_templating ->  0.0 seconds\n",
      "        |_llm ->  650.213329 seconds\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>  Certainly! Based on the provided context information, I can help you combine the learning styles from the document and generate a few game types based on the Octalysis framework for different types of games.\n",
       "\n",
       "Here are some game ideas that incorporate multiple learning styles and the Octalysis framework:\n",
       "\n",
       "1. Virtual Reality (VR) Exploration Games for Visual, Kinesthetic, and Naturalistic Learners:\n",
       "\t* Game Idea: \"Eco-Warriors VR\" - A nature-based VR game where players explore a virtual ecosystem, restore balance, and defend against threats. Players can interact with the environment using hand gestures or voice commands, and receive feedback through visual cues and sounds.\n",
       "2. Strategy-based Simulation Games for Logical, Kinesthetic, and Solitary Learners:\n",
       "\t* Game Idea: \"City Builder\" - A city-building simulation game where players manage resources, plan developments, and address real-time challenges to grow their city. Players can use logical reasoning to solve problems, manipulate objects in the virtual space using gestures or mouse clicks, and receive feedback through visual progress indicators.\n",
       "3. Rhythm and Sound Puzzle Games for Auditory, Kinesthetic Learners:\n",
       "\t* Game Idea: \"Beat Blaster\" - A music-based puzzle game where players match beats and rhythms to succeed. Players can use their sense of hearing and timing to complete levels, and receive feedback through sound effects and visual cues.\n",
       "4. AR Outdoor Quests for Naturalistic, Social, and Kinesthetic Learners:\n",
       "\t* Game Idea: \"Wildlife Explorer\" - An augmented reality game where players embark on outdoor quests to discover virtual objects in nature, collaborate with others in real-time, and compete in environmental challenges. Players can use their sense of exploration and collaboration to succeed, and receive feedback through AR visuals and sounds.\n",
       "5. Trivia and Quiz Challenges for Read/Write, Social, and Logical Learners:\n",
       "\t* Game Idea: \"QuizUp\" - A trivia game that challenges players to answer questions, compete in teams, and solve complex puzzles. Players can use their reading comprehension skills to absorb information, logical reasoning to solve problems, and social skills to collaborate with others. Feedback is provided through visual progress indicators, sounds, and leaderboards.\n",
       "\n",
       "These game ideas incorporate multiple learning styles and the Octalysis framework to create engaging and well-rounded learning experiences. By combining different game mechanics and motivational drivers, these games can cater to a wide range of learners and preferences.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query your index!\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "query_engine = index.as_query_engine(service_context=service_context,\n",
    "                                     similarity_top_k=3)\n",
    "\n",
    "# response = query_engine.query(\"What do you think of Facebook's LLaMa?\")\n",
    "# print(response)\n",
    "\n",
    "# query = \"What is the Alien nuclear agenda? \\n\\n\" \\\n",
    "#         \"Please summarize the information into 3 detailed paragraphs, something suitable for a blog post.\"\n",
    "\n",
    "query = \"could you combine the learning styles from the document and generate a few game types based on the octalysis framework for different types of games\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  643.355441 seconds\n",
      "      |_retrieve ->  0.601479 seconds\n",
      "        |_embedding ->  0.546591 seconds\n",
      "      |_synthesize ->  642.753737 seconds\n",
      "        |_templating ->  0.0 seconds\n",
      "        |_llm ->  642.674986 seconds\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>  Sure, I'd be happy to help! Based on the context information provided, here are five multiple-choice questions related to sexual harassment that could be incorporated into a narrative-driven adventure game for adult learning:\n",
       "\n",
       "1. What is considered appropriate behavior in a professional setting to avoid being perceived as sexually harassing someone?\n",
       "a) Being overly flirtatious and making explicit comments\n",
       "b) Asking about someone's personal life or relationships\n",
       "c) Offering to help with tasks or providing support without expectation of reciprocity\n",
       "d) All of the above are appropriate behaviors\n",
       "\n",
       "Answer: c) Offering to help with tasks or providing support without expectation of reciprocity.\n",
       "\n",
       "2. Which of the following is an example of quid pro quo sexual harassment?\n",
       "a) A supervisor offering a subordinate a promotion in exchange for a date\n",
       "b) A coworker making explicit comments to a colleague in the break room\n",
       "c) A manager asking an employee out on a date and being rejected\n",
       "d) All of the above are examples of quid pro quo sexual harassment\n",
       "\n",
       "Answer: a) A supervisor offering a subordinate a promotion in exchange for a date.\n",
       "\n",
       "3. What is the purpose of the Title IX legislation in the United States?\n",
       "a) To prohibit discrimination based on gender in education\n",
       "b) To protect employees from sexual harassment in the workplace\n",
       "c) To provide legal recourse for victims of sexual harassment\n",
       "d) All of the above\n",
       "\n",
       "Answer: a) To prohibit discrimination based on gender in education.\n",
       "\n",
       "4. What is an example of a hostile work environment?\n",
       "a) A coworker making offensive comments about someone's appearance\n",
       "b) A supervisor who consistently gives unfair performance reviews to one employee\n",
       "c) A workplace that is physically unsafe or has hazardous conditions\n",
       "d) All of the above are examples of a hostile work environment\n",
       "\n",
       "Answer: d) All of the above are examples of a hostile work environment.\n",
       "\n",
       "5. What should an employee do if they experience or witness sexual harassment in the workplace?\n",
       "a) Ignore the behavior and hope it stops\n",
       "b) Report the behavior to HR or a supervisor\n",
       "c) Talk to the person engaging in the behavior and try to resolve the issue\n",
       "d) All of the above are appropriate actions\n",
       "\n",
       "Answer: b) Report the behavior to HR or a supervisor.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query your index!\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "query_engine = index.as_query_engine(service_context=service_context,\n",
    "                                     similarity_top_k=3)\n",
    "\n",
    "# response = query_engine.query(\"What do you think of Facebook's LLaMa?\")\n",
    "# print(response)\n",
    "\n",
    "# query = \"What is the Alien nuclear agenda? \\n\\n\" \\\n",
    "#         \"Please summarize the information into 3 detailed paragraphs, something suitable for a blog post.\"\n",
    "\n",
    "query = \"I am trying to develop a game to enhance adult learning learning \\n\\n\" \\\n",
    "        \"Given that the game is a narrative driven adventure game, please generate 5 multiple choice question regarding sexual harrassment \\n\\n\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
